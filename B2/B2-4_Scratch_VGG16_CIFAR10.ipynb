{"cells":[{"cell_type":"markdown","metadata":{"id":"u_F7X_MXPtSy"},"source":["学生証番号 :\n","\n","名前 :\n","\n","メールアドレス(法政大学) :"]},{"cell_type":"markdown","metadata":{"id":"4cSzfJmxM9_J"},"source":["# B2-4 VGG16ネットワークを用いた学習\n","\n","拡大したCIFAR10画像をVGGネットワークの構造で学習するモデルを構築する。\n","\n","もともと用いていたImageNet用の1000次元の出力を取り外し、CIFAR10用の10次元の出力に取り換える。\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1RlOO0sQDVt6Y8l9lF34yZHb5F7_IEZf8\" width = 50%></img>\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1G0WQ5MaVpHRCktqHBiGbHARPb_MlGIDd\" width = 50%></img>\n","\n","\n","VGGネットワークは先ほどのB-1実験で試したネットワークよりかなり大規模である。\n","ここではCIFAR10データセットの学習を試みる。\n","\n","ただし、深いネットワークに32$\\times$32の小さい画像を入力すると、途中のpoolingで画像サイズがなくなってしまうため、ここの実験では（無駄だが）縦横約5倍の160$\\times$160にして入力する。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mKiDkeaM6eH"},"outputs":[],"source":["# [1-0]\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import vgg16\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"LUWdjojmRUSq"},"source":["## データセットの準備"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrUhLQJPC2f0"},"outputs":[],"source":["# [1-1]\n","def get_data(data_name=\"CIFAR10\"):\n","    if data_name == \"CIFAR100\":\n","        (X_train, y_train), (X_test, y_test) = keras.datasets.cifar100.load_data()\n","    else:\n","        (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n","    y_train = y_train.flatten()\n","    y_test = y_test.flatten()\n","    return (X_train, y_train), (X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fg9VA3DbDSz_"},"outputs":[],"source":["# [1-2]\n","# 予測ラベルの名前を所持しておく\n","target_names = [\n","    \"airplane\",\n","    \"automobile\",\n","    \"bird\",\n","    \"cat\",\n","    \"deer\",\n","    \"dog\",\n","    \"frog\",\n","    \"horse\",\n","    \"ship\",\n","    \"truck\",\n","]\n","\n","\n","def random_plot(X, y, predict=None):\n","    W = 10\n","    H = 5\n","    fig = plt.figure(figsize=(10, 20))\n","    fig.subplots_adjust(left=0, right=1, bottom=0, top=0.3, hspace=0.10, wspace=0.10)\n","    for i in range(5):\n","        for j in range(10):\n","            x_tmp = X[y == j]\n","            idx = np.random.randint(len(x_tmp))\n","            x = x_tmp[idx].reshape(32, 32, 3)\n","            ax = fig.add_subplot(H, W, (i * 10) + j + 1, xticks=[], yticks=[])\n","            ax.imshow(x)\n","            if predict is not None:\n","                pred_tmp = predict[y == j]\n","                p = pred_tmp[idx]\n","                ax.set_title(f\"{j} -> {p}\")\n","            else:\n","                ax.set_title(target_names[j])"]},{"cell_type":"markdown","metadata":{"id":"0EGD9Kn5MW-9"},"source":["以下の `DATASET` に `CIFAR100` を指定すると、100クラスの分類タスクのCIFAR100のデータセットがダウンロードできる。\n","この実験は、CIFAR10を行うが、興味がある人は別途CIFAR100を試してみてもよい。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-nQwWW9RY6p"},"outputs":[],"source":["# [1-3]\n","DATASET = \"CIFAR10\"\n","# CIFAR100を使用したい場合は以下をコメントアウト\n","# CIFAR100の場合はrandom_plotが全てのラベルを表示しないので注意\n","# DATASET = \"CIFAR100\"\n","(X_train, y_train), (X_test, y_test) = get_data(DATASET)\n","\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDcD9hcsNpv0"},"outputs":[],"source":["# [1-4]\n","# 学習用データを覗いてみる。\n","# 複数回実行すると画像も変化する。\n","random_plot(X_train, y_train)"]},{"cell_type":"code","source":[],"metadata":{"id":"2sv6ZcUCL4eL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KB98zjcRRHeD"},"source":["### モデルの準備\n","B2-3の実験と違い、**pre-trainされていない**VGG16モデルをロードする。\n","入力サイズをVGG16のもともとの224$\\times$224から、160$\\times$160に変更する。\n","\n","(注：これは、CIFAR10の画像がもともと32x32の大きさしかなく、VGG16にそのまま入力すると、途中のpoolingの処理で画像サイズが1より小さくなってしまうため、単純に縦横5倍にする処理のためである。＝本質的には大きな無駄だが、簡単な実行のため今回はこのようにしている）\n","\n","include_top=Falseとして、Conv5_3をmax poolingしたところまでのネットワークになっており、プログラムではここまでのネットワークを\"core\"と呼んでいる。  \n","\n","今回は、CIFAR10の画像の認識を行うので、新たにCIFAR10用に10次元の出力をつなげる.\n","（100種類の認識を行うCIFAR100なら100次元）\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1RlOO0sQDVt6Y8l9lF34yZHb5F7_IEZf8\" width = 50%></img>\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1G0WQ5MaVpHRCktqHBiGbHARPb_MlGIDd\" width = 50%></img>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=17ielhT-JYIzLwmIENxcPLiO8O5n21YTc\" width = 50%></img>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VQ5LOMAN5llA"},"source":["VGG16モデルの入力～Conv5_3後のmax poolingまでをdownload (include_top=Falseとすると、全結合層なしの部分のみダウンロード）する。  \n","weights=None としているので、事前学習の重みではなく、乱数で初期化された重みを利用。  \n","つまりここでは、このモデルの重みを乱数の状態から（ゼロから：スクラッチともいう）学習し、その様子と成果を観察する。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cf9gcnNIOBZC"},"outputs":[],"source":["# [1-5]\n","# VGG16をCIFAR10ように改良したモデルを読み込む関数を定義\n","def get_vgg16_model(data_name=\"CIFAR10\"):\n","    num_output = 10 if data_name == \"CIFAR10\" else 100\n","    # change input image size 224x224 -> 160x160\n","    # conv5_3のあとのmax poolまでのネットワーク(core)の出力をflattenした後、\n","    # 全結合層を介して10次元の出力をつなげる\n","    model = keras.Sequential(\n","        [\n","            keras.Input(shape=(None, None, 3)),\n","            keras.layers.Lambda(\n","                lambda img: tf.image.resize(img, (160, 160)), name=\"resize\"\n","            ),\n","            keras.layers.Lambda(\n","                tf.keras.applications.vgg16.preprocess_input, name=\"preprocess\"\n","            ),\n","            # VGGのCNN部分\n","            keras.applications.VGG16(\n","                include_top=False,\n","                weights=None,\n","            ),\n","            keras.layers.Flatten(),\n","            keras.layers.Dense(num_output, activation=\"softmax\"),\n","        ]\n","    )\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GmZ6edPErpQ"},"outputs":[],"source":["# [1-6]\n","# モデルの読みこみ\n","model = get_vgg16_model(DATASET)\n","\n","# モデルの全体図の概要\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMITdmxXE2Al"},"outputs":[],"source":["# [1-7]\n","# VGG部分の概要確認\n","model.layers[2].summary()"]},{"cell_type":"markdown","metadata":{"id":"X1qxjRsLYIBh"},"source":["### モデルのセットアップ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQNqyktCEQ8G"},"outputs":[],"source":["# [1-8]\n","# 誤差関数と最適化手法を設定する関数を作成する。\n","def model_setup(model, optimizer=\"adam\", lr=0.001):\n","    if optimizer == \"adam\":\n","        optim = keras.optimizers.Adam(learning_rate=lr)\n","    elif optimizer == \"sgd\":\n","        optim = keras.optimizers.SGD(learning_rate=lr)\n","    else:\n","        raise ValueError\n","    model.compile(\n","        loss=\"sparse_categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9sSymX9YHxE"},"outputs":[],"source":["# [1-9]\n","model_setup(model)\n","# 改めてネットワークの構成を確認。モデルパラメータの数が学習パラメータの数と一致していること\n","# 学習されるパラメータの数を確認しておく。\n","# （これでも大規模な全結合層　flatten-4096-4096-1000 を外しているので総数は普通のVGG16 の1/10程度になっている）\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"k5L57Kj5YzbL"},"source":["\n","# VGG16のスクラッチ学習\n","最初に学習前のモデルで予測を行い、性能を確認する。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogK29to2YwbL"},"outputs":[],"source":["# [1-10]\n","# テストデータで評価する\n","loss_no_train, accuracy_no_train = model.evaluate(X_test, y_test, verbose=0)\n","print(\"学習前の誤差 : \", loss_no_train)\n","print(\"学習前の正解率 : \", accuracy_no_train)"]},{"cell_type":"markdown","metadata":{"id":"aom5pzluZX60"},"source":["学習にはかなりの時間がかかるため、実験時間内では2、3epoch程度のみの学習しか行わない。\n","学習の傾向に関しては事前に実行した時のログから確認する。\n","\n","※ レポートには10epochで学習したモデルの結果のグラフや、予測などを確認してほしいので授業外でEPOCHの値を10にして全体を実行しなおすこと。すべて実行完了するまでに１時間ほどかかるが、ヘッダーの「ランタイム」タブの「再起動してすべてのセルを実行」を行うことで全体を実行してくれる。\n","１時間放置していると自動でセッションが切れてしまうので、定期的に確認すること。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JKMw3tCYsTF"},"outputs":[],"source":["# [1-11]\n","# 実際に学習を行う。\n","EPOCH = 2\n","# ここを10にして再度実行する。\n","# EPOCH = 10\n","batch_size = 128\n","\n","trainlog = model.fit(\n","    X_train, y_train, epochs=EPOCH, validation_split=0.1, batch_size=batch_size\n",")"]},{"cell_type":"markdown","metadata":{"id":"t0l_M4wCGsTg"},"source":["（参考）以下が10epoch学習を行った時のログ。レポートでは必ず自分の実施データに基づいた結果の報告及び考察を行うこと。\n","```\n","Epoch 1/10\n","352/352 [==============================] - 584s 2s/step - loss: 2.6456 - accuracy: 0.3136 - val_loss: 1.4932 - val_accuracy: 0.4668\n","Epoch 2/10\n","352/352 [==============================] - 537s 2s/step - loss: 1.3005 - accuracy: 0.5424 - val_loss: 1.1119 - val_accuracy: 0.6076\n","Epoch 3/10\n","352/352 [==============================] - 537s 2s/step - loss: 0.9844 - accuracy: 0.6556 - val_loss: 0.8443 - val_accuracy: 0.7066\n","Epoch 4/10\n","352/352 [==============================] - 539s 2s/step - loss: 0.7829 - accuracy: 0.7253 - val_loss: 0.8082 - val_accuracy: 0.7214\n","Epoch 5/10\n","352/352 [==============================] - 539s 2s/step - loss: 0.6410 - accuracy: 0.7777 - val_loss: 0.7941 - val_accuracy: 0.7364\n","Epoch 6/10\n","352/352 [==============================] - 535s 2s/step - loss: 0.5138 - accuracy: 0.8228 - val_loss: 0.7513 - val_accuracy: 0.7556\n","Epoch 7/10\n","352/352 [==============================] - 533s 2s/step - loss: 0.3974 - accuracy: 0.8612 - val_loss: 0.8566 - val_accuracy: 0.7470\n","Epoch 8/10\n","352/352 [==============================] - 533s 2s/step - loss: 0.3035 - accuracy: 0.8943 - val_loss: 0.9897 - val_accuracy: 0.7284\n","Epoch 9/10\n","352/352 [==============================] - 533s 2s/step - loss: 0.2400 - accuracy: 0.9155 - val_loss: 1.0662 - val_accuracy: 0.7436\n","Epoch 10/10\n","352/352 [==============================] - 532s 2s/step - loss: 0.2007 - accuracy: 0.9306 - val_loss: 0.9919 - val_accuracy: 0.7514\n","```\n","学習が進んでいることがわかる。パラメターの数が多いため、過学習の傾向も確認できる。（どこからそれが言えるか？）"]},{"cell_type":"markdown","metadata":{"id":"DHZJhNxQs50T"},"source":["## 学習ログの可視化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMwmKTdWZdx8"},"outputs":[],"source":["# [1-12]\n","# 学習曲線を描画する関数の作成\n","def plot_result(log):\n","    fig = plt.figure(figsize=(10, 3))\n","    ax1 = fig.add_subplot(1, 2, 1)\n","    ax1.plot(log.history[\"accuracy\"])\n","    ax1.plot(log.history[\"val_accuracy\"])\n","    ax1.set_title(\"Model accuracy\")\n","    ax1.set_ylabel(\"Accuracy\")\n","    ax1.set_xlabel(\"Epoch\")\n","    ax1.legend([\"Train\", \"Validation\"], loc=\"best\")\n","    ax2 = fig.add_subplot(1, 2, 2)\n","    ax2.plot(log.history[\"loss\"])\n","    ax2.plot(log.history[\"val_loss\"])\n","    ax2.set_title(\"Model loss\")\n","    ax2.set_ylabel(\"Loss\")\n","    ax2.set_xlabel(\"Epoch\")\n","    ax2.legend([\"Train\", \"Validation\"], loc=\"best\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PWdq9UZdv8P"},"outputs":[],"source":["# [1-13]\n","# 実際に学習曲線の確認\n","# 右が正解率を左が誤差の推移を表している。\n","plot_result(trainlog)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFtv19EajN-G"},"outputs":[],"source":["# [1-14]\n","# 評価\n","loss_train, accuracy_train = model.evaluate(X_test, y_test, verbose=0)\n","\n","# 学習前のスコアの表示\n","print(\"学習前の誤差 : \", loss_no_train)\n","print(\"学習前の正解率 : \", accuracy_no_train)\n","\n","# 学習後のスコアの表示\n","print(\"===== 学習後 =====\")\n","print(f\"学習後の誤差 :  \", loss_train)\n","print(f\"学習後の正解率 : \", accuracy_train)"]},{"cell_type":"markdown","metadata":{"id":"iSrJnMs88xc2"},"source":["## 課題 B2-4-1 モデルの学習時間と認識精度の関係およびエラー解析\n","VGG-16を学習するためにかかった時間はどのくらいかかったか。\n","また、学習したパラメータ数はいくつであったか。確認せよ。\n","また、それぞれの時の画像認識せ学習回数に対して、どの程度のどんな画像の認識に正解し、どんな画像の認識に失敗したか。以下のコードを参考に画像を確認して考察せよ。  \n","- 予測が正解しているデータの表示\n","```\n","# モデルの予測\n","test_predict = np.argmax(model.predict(X_test), 1)\n","# 正解しているデータの取得\n","true_idx = test_predict == y_test\n","# 正解しているデータの可視化\n","random_plot(X_test[true_idx], y_test[true_idx], test_predict[true_idx])\n","```\n","\n","- 予測が間違っているデータの表示\n","```\n","# モデルの予測\n","test_predict = np.argmax(model.predict(X_test), 1)\n","# 間違えているデータの取得\n","false_idx = test_predict != y_test\n","# 間違っているデータの可視化\n","random_plot(X_test[false_idx], y_test[false_idx], test_predict[false_idx])\n","```\n","\n","それぞれ実行毎にデータは変わっていくため、多く実行することで失敗の傾向が確認できる。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V5rdxHrOL4Z"},"outputs":[],"source":["# ここから実験を追加する。(自由にセルを増やしてOK)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}