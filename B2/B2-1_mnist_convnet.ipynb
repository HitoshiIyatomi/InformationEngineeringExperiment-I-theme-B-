{"cells":[{"cell_type":"markdown","metadata":{"id":"TYKfSRpBPFCY"},"source":["学生証番号 :\n","\n","名前 :\n","\n","メールアドレス(法政大学) :"]},{"cell_type":"markdown","metadata":{"id":"NIZgWgq_IdLD"},"source":["# B2-1 convolutional neural networks (CNN) 入門\n","\n","B2実験では、深層学習技術の中核を担うConvolutional Neural networks (CNN) について学ぶ。\n","\n","具体的なCNNの説明は配布資料に譲るが、CNNは2次元画像全体をそのまま入力として受け取り、認識に必要な特徴抽出をモデル自身で行い、優れた認識性能を示す。\n","\n","まずB2-1では、CNNの挙動や結果について実際のコードを動かしながら学ぶ。"]},{"cell_type":"markdown","metadata":{"id":"0jjR2DwnIdLH"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QzKQySjIdLI"},"outputs":[],"source":["# [1-0]\n","import numpy as np\n","import math\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"P_100MtzIdLI"},"source":["## データの準備\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qeAoMNFIdLI"},"outputs":[],"source":["# [1-1]\n","# get_data関数の定義\n","# B1-2の時とは異なり画像で扱うためflatten（2次元データ＞ベクトル化の処理）は削除\n","# data_sizeは学習データの数を絞るために使用\n","def get_data_mnist(data_size=None):\n","    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n","    # 0 ~ 1の範囲に正規化を行う\n","    X_train = X_train.astype(np.float32) / 255.0\n","    X_test = X_test.astype(np.float32) / 255.0\n","    X_train = np.expand_dims(X_train, -1)\n","    X_test = np.expand_dims(X_test, -1)\n","    if data_size is not None:\n","        X_train = X_train[:data_size]\n","        y_train = y_train[:data_size]\n","    return (X_train, y_train), (X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oku0f0GnLe32"},"outputs":[],"source":["# [1-2]\n","(X_train, y_train), (X_test, y_test) = get_data_mnist()\n","print(f\"X_train shape : {X_train.shape} \")\n","print(f\"X_test shape  : {X_test.shape} \")\n","print(f\"y_train shape : {y_train.shape} \")\n","print(f\"y_test shape  : {y_test.shape} \")"]},{"cell_type":"markdown","metadata":{"id":"ya7NEsaKIdLJ"},"source":["## CNNモデルの構築\n","\n","このモデルは、5x5の畳み込みフィルタを持つ畳み込み層を1層だけ持ち、そのあとに2x2のmaxpoolによるサイズの1/4化、(12x12のフィルタが32個)そのあとに、それらを1次元化して（4608次元）、20次元へ次元削減する全結合層(linear1)、さらに10次元に減らす全結合層(linear2)を介して出力層（10ノード）のきわめてシンプルなCNNモデルである。\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1xtvxqBtA0qeHe3JwyGtS27yBWxyC_IR9\" width = 80%></img>\n","\n","\n","4608-20-10次元の部分は、先ほどの3層BPNNと同じである。\n","\n","入力のチャネル$C$が1なのは、grayscale画像だから。\n","カラー画像だとR,G,Bの3になる。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpy3DjlpIdLJ"},"outputs":[],"source":["# [1-3]\n","# KerasによるCNNの定義\n","model = keras.Sequential(\n","    [\n","        layers.InputLayer(input_shape=(28, 28, 1)),\n","        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(20, activation=\"relu\"),\n","        layers.Dense(10, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"kIDvQ50ZQr3n"},"source":["学習前に、得られている畳み込みフィルタを可視化してみる。\n","\n","5x5(x1)のフィルタが32個ある。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQvBC22UNEmI"},"outputs":[],"source":["# [1-4]\n","# フィルターを可視化するための関数\n","# modelには可視化したいモデルを、layer_idには何番目のconv層のfilterを見るかのパラメータを渡す。\n","def plot_conv_filter(model, layer_id):\n","    conv_layers = [layer for layer in model.layers if \"conv\" in layer.name]\n","    if layer_id >= len(conv_layers):\n","        print(f\"{layer_id} conv layer is not found\")\n","        return None\n","    target_layer = conv_layers[layer_id]\n","    filter, bias = target_layer.get_weights()\n","    print(f\"layer name : {target_layer.name}\")\n","    print(f\"filter shape : {filter.shape}\")\n","    print(f\"bias shape : {bias.shape}\")\n","    num_filter = filter.shape[-1]\n","\n","    cols = 8\n","    rows = math.ceil(num_filter / cols)\n","    idx = 1\n","    fig = plt.figure(figsize=(cols, rows))\n","    for i in range(rows):\n","        for j in range(cols):\n","            if idx > num_filter:\n","                continue\n","            ax = fig.add_subplot(rows, cols, idx, xticks=[], yticks=[])\n","            ax.imshow(filter[:, :, 0, idx - 1], cmap=\"gray\")\n","            idx += 1\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8z9JNcKtNSaA"},"outputs":[],"source":["# [1-5]\n","# 1層目のフィルターの可視化\n","plot_conv_filter(model, 0)"]},{"cell_type":"markdown","metadata":{"id":"TI4fhWwMSF73"},"source":["まだ学習を行っていないため、ランダムな値になっている。"]},{"cell_type":"markdown","metadata":{"id":"TNTV4hxeIdLJ"},"source":["## モデルのコンパイルと初期値の性能確認\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tS9W7TdRa6d"},"outputs":[],"source":["# [1-6]\n","# 誤差関数と最適化手法を設定する関数を作成する。\n","def model_setup(model, optimizer=\"adam\", lr=0.001):\n","    if optimizer == \"adam\":\n","        optim = keras.optimizers.Adam(learning_rate=lr)\n","    elif optimizer == \"sgd\":\n","        optim = keras.optimizers.SGD(learning_rate=lr)\n","    else:\n","        raise ValueError\n","    model.compile(\n","        loss=\"sparse_categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmJvwH6WRkcp"},"outputs":[],"source":["# [1-7]\n","# モデルのセットアップ。\n","model_setup(model)\n","\n","# 学習前のモデルをテストデータで評価する\n","loss_no_train, accuracy_no_train = model.evaluate(X_test, y_test, verbose=0)\n","print(\"学習前の誤差 : \", loss_no_train)\n","print(\"学習前の正解率 : \", accuracy_no_train)"]},{"cell_type":"markdown","metadata":{"id":"bM05jfo0VV_h"},"source":["## CNNモデルの学習\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8T1z9g2VMg9"},"outputs":[],"source":["# [1-8]\n","# 学習を実行する。\n","# パラメータの設定\n","batch_size = 128\n","epochs = 10\n","# 学習回数は上で10回と定義している。\n","trainlog = model.fit(\n","    X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1\n",")"]},{"cell_type":"markdown","metadata":{"id":"DSIVKdT1VX-S"},"source":["## 得られた結果のログから学習曲線を描画する。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3V9kPKpeMBde"},"outputs":[],"source":["# [1-9]\n","# 学習曲線を描画する関数の作成\n","def plot_result(log):\n","    fig = plt.figure(figsize=(10, 3))\n","    ax1 = fig.add_subplot(1, 2, 1)\n","    ax1.plot(log.history[\"accuracy\"])\n","    ax1.plot(log.history[\"val_accuracy\"])\n","    ax1.set_title(\"Model accuracy\")\n","    ax1.set_ylabel(\"Accuracy\")\n","    ax1.set_xlabel(\"Epoch\")\n","    ax1.legend([\"Train\", \"Validation\"], loc=\"best\")\n","    ax2 = fig.add_subplot(1, 2, 2)\n","    ax2.plot(log.history[\"loss\"])\n","    ax2.plot(log.history[\"val_loss\"])\n","    ax2.set_title(\"Model loss\")\n","    ax2.set_ylabel(\"Loss\")\n","    ax2.set_xlabel(\"Epoch\")\n","    ax2.legend([\"Train\", \"Validation\"], loc=\"best\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0Cfr03fSsG4"},"outputs":[],"source":["# [1-10]\n","# 実際に学習曲線の確認\n","# 右が正解率を左が誤差の推移を表している。\n","plot_result(trainlog)"]},{"cell_type":"markdown","metadata":{"id":"qi5_uFksQ3kE"},"source":["## 学習後の畳み込みフィルタの可視化\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2jVelSwKxio"},"outputs":[],"source":["# [1-11]\n","# 学習後のフィルターの可視化\n","plot_conv_filter(model, layer_id=0)"]},{"cell_type":"markdown","metadata":{"id":"sFi58tuJarqA"},"source":["初期値のフィルタに比べて、濃淡がはっきりと分かれるようになった。"]},{"cell_type":"markdown","metadata":{"id":"lTEZqKSnIdLK"},"source":["## テストデータに対する性能の評価"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"baFKX57bIdLK"},"outputs":[],"source":["# [1-12]\n","# 評価\n","loss_train, accuracy_train = model.evaluate(X_test, y_test, verbose=0)\n","\n","# 学習前のスコアの表示\n","print(\"学習前の誤差 : \", loss_no_train)\n","print(\"学習前の正解率 : \", accuracy_no_train)\n","\n","# 学習後のスコアの表示\n","print(\"===== 学習後 =====\")\n","print(f\"学習後の誤差 :  \", loss_train)\n","print(f\"学習後の正解率 : \", accuracy_train)"]},{"cell_type":"markdown","metadata":{"id":"KD9Qkc4WcNHg"},"source":["学習が終わってきちんと精度よく識別できることが確認できた。\n","（この課題はBPNNでもできていた）"]},{"cell_type":"markdown","metadata":{"id":"BNpkzHfacFNm"},"source":["## モデルが予測を間違えたデータの確認。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsE3YkYMcO9y"},"outputs":[],"source":["# [1-13]\n","# データを表示する関数の作成\n","# Xにはデータをyにはそれに対応する正解ラベルを渡す\n","def random_plot(X, y, predict=None):\n","    W = 10\n","    H = 5\n","    fig = plt.figure(figsize=(10, 20))\n","    fig.subplots_adjust(left=0, right=1, bottom=0, top=0.3, hspace=0.10, wspace=0.10)\n","    for i in range(5):\n","        for j in range(10):\n","            x_tmp = X[y == j]\n","            idx = np.random.randint(len(x_tmp))\n","            x = x_tmp[idx].reshape(28, 28)\n","            ax = fig.add_subplot(H, W, (i * 10) + j + 1, xticks=[], yticks=[])\n","            ax.imshow(x, cmap=\"gray\")\n","            if predict is not None:\n","                pred_tmp = predict[y == j]\n","                p = pred_tmp[idx]\n","                ax.set_title(f\"{j} -> {p}\")\n","            else:\n","                ax.set_title(f\"label : {j}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dII6dtFlcWJk"},"outputs":[],"source":["# [1-14]\n","# モデルの予測を取得。\n","test_predict = np.argmax(model.predict(X_test), 1)\n","# 間違えたものに絞って表示\n","false_idx = y_test != test_predict\n","# 間違えたもののみを描画\n","random_plot(X_test[false_idx], y_test[false_idx], test_predict[false_idx])"]},{"cell_type":"markdown","metadata":{"id":"cEluCNru3_jB"},"source":["## 課題 B2-1-1 CNNの学習後のフィルタの考察\n","学習によって畳み込みフィルタは、どうしてこのようなパターン（[1-11]を参照）になったのかについて考えよ。"]},{"cell_type":"markdown","metadata":{"id":"4SnMbSjla7AO"},"source":["## 課題 B2-1-2 BPNN(前回のB1-2)との比較\n","データ数を減らした状態で(data_size=600)CNNのモデルを学習させ、性能を確認せよ。また、BPNNの時と比べて性能はどうか。またその差はなぜ起こったと考えらえるか。\n","\n","\n","ヒント :\n","- データ数を変更する場合は以下のコードを使用（データを上書きしてしまうので嫌なら変数名を変え、学習に渡すときも注意する）\n","```\n","data_size = 600\n","(X_train, y_train), _ = get_data_mnist(data_size=data_size)\n","```\n","- モデル構造や学習率の設定\n","```\n","model = keras.Sequential(\n","    [\n","        layers.InputLayer(input_shape=(28, 28, 1)),\n","        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(128, activation=\"relu\"),     \n","        layers.Dense(10, activation=\"softmax\"),\n","    ]\n",")\n","# 定義したモデルを確認\n","model.summary()\n","# 学習率の変更\n","lr = 0.001\n","model_setup(model, lr=lr)\n","```\n","- 学習のパラメータ(バッチサイズやエポック数)を設定\n","```\n","epochs=50\n","batch_size = 128\n","log = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n","```\n","- 評価するとき\n","```\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"誤差　: \", loss)\n","print(\"正解率 : \", accuracy)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHUb-E1xOQCn"},"outputs":[],"source":["# ここから実験を追加する。(自由にセルを増やしてOK)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/mnist_convnet.ipynb","timestamp":1620614213048}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}