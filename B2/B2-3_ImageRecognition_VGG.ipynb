{"cells":[{"cell_type":"markdown","metadata":{"id":"HL1Hk-phPprg"},"source":["学生証番号 :\n","\n","名前 :\n","\n","メールアドレス(法政大学) :"]},{"cell_type":"markdown","metadata":{"id":"sx0lfgvp3p5W"},"source":["# B2-3 事前学習済のCNN(VGG16モデル）を用いた画像認識体験\n","\n","\n","1000クラス120万枚のImageNet画像セットを事前に学習しているVGG16モデルを用いて、画像の認識体験を行う\n","\n","VGG16モデルは、2014年のILSVRCで優勝した、畳み込み層と全結合層併せて16層からなるCNNモデルである。\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1l4qf_ohJpsagRznuFkt2C8ETK5gilYxp\" width = 70%></img>\n","\n","224$\\times$224の画像を受け付けて、それが学習済みの1000クラスのうちどれにあたるかを推定する。\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QW1f3NyUvt3h"},"outputs":[],"source":["# [1-0]\n","# ライブラリのインポート\n","from tensorflow.keras.applications import xception\n","from tensorflow.keras.applications import vgg16\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","import PIL\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGUNRQOoxNKX"},"outputs":[],"source":["# [1-1]\n","# モデルを呼び出す関数\n","def get_model(arch=\"vgg\"):\n","    if arch == \"vgg\":\n","        return vgg16.VGG16(weights=\"imagenet\", include_top=True)\n","    elif arch == \"xception\":\n","        return xception.Xception(weights=\"imagenet\", include_top=True)\n","    else:\n","        print(\"ARCH not Found\")\n","        return None\n","\n","\n","# 画像をリサイズする関数(モデルに合わせて大きさを変更)\n","def resize(img, arch):\n","    if arch == \"vgg\":\n","        return img.resize((224, 224))\n","    elif arch == \"xception\":\n","        return img.resize((299, 299))\n","    else:\n","        print(\"ARCH not Found\")\n","        return None\n","\n","\n","# 画像をリサイズし正規化を行う関数(モデルに合わせて変更)\n","def preprocess_input(img, arch=\"vgg\", use_normalize=True):\n","    img = resize(img, arch)\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    if use_normalize:\n","        if arch == \"vgg\":\n","            return vgg16.preprocess_input(x)\n","        elif arch == \"xception\":\n","            return xception.preprocess_input(x)\n","        else:\n","            print(\"ARCH not Found\")\n","            return None\n","    else:\n","        return x\n","\n","\n","# 予測された確率から、上位をラベルと一緒に返す関数\n","def decode_predictions(preds, arch=\"vgg\", top=5):\n","    if arch == \"vgg\":\n","        return vgg16.decode_predictions(preds, top)\n","    elif arch == \"xception\":\n","        return xception.decode_predictions(preds, top)\n","    else:\n","        print(\"ARCH not Found\")\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqRrInb0y2px"},"outputs":[],"source":["# [1-2]\n","# モデルの設定\n","ARCH = \"vgg\"\n","# Xceptionを使用する場合は以下のコメントを外す。\n","# ARCH = \"Xception\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqCs2o04v0yS"},"outputs":[],"source":["# [1-3]\n","# 学習済みのモデルを読み込む\n","model = get_model(ARCH)\n","# モデルの概要を表示\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"ZaouY9Rb4jaa"},"source":["最後のprediction (Dense)と書かれているところは、1000種類の認識対象に対応した1000次元のベクトルである。\n","\n","この表示だけではわからないが、このモデルの出力はsoftmaxになっているので、1000次元の出力は対応する各クラスの確率になっており、1000次元の合計値は1である。\n"]},{"cell_type":"markdown","metadata":{"id":"AYOiCdoG3r6k"},"source":["## 自前のデータの用意\n","\n","認識したい(試したい）画像を用意します。右のタブのフォルダのマークをクリックし、下の画像に従って画像のアップロードを行ってください。\n","\n","![](https://i.imgur.com/VP6Dfeb.png)\n","\n","パスのコピーまでできたら以下の `img_path = ` に続く部分にシングルクォートかダブルクォートで挟んでペーストしてください。\n"]},{"cell_type":"code","source":["# [1-4]\n","####################################\n","# 自分の画像で試したい場合、そのファイルをColab上において指定する。\n","# 以下にパスを指定する。\n","img_path = 'DSC_1775.JPG'\n","img = image.load_img(img_path)\n","#############################################\n","\n","# 画像の表示\n","plt.imshow(img)"],"metadata":{"id":"u2ZclHkULCn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fr-oWyC5wpJy"},"outputs":[],"source":["# [1-4]\n","####################################\n","# 自分の画像で試したい場合、そのファイルをColab上において指定する。\n","# 以下にパスを指定する。\n","img_path = \"'\n","img = image.load_img(img_path)\n","#############################################\n","\n","# 画像の表示\n","plt.imshow(img)"]},{"cell_type":"markdown","metadata":{"id":"bzTfiUyXAeFE"},"source":["機械的に指定のサイズ(VGGなら224$\\times$224)になるので、長方形の画像を入れるとつぶれることに注意。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jjBnm6Xswgxc"},"outputs":[],"source":["# [1-5]\n","# リサイズ後の画像を表示\n","resized_img = resize(img, ARCH)\n","plt.imshow(resized_img)"]},{"cell_type":"markdown","metadata":{"id":"x21kcq8OJaRF"},"source":["指定の入力サイズになった画像の各色$x$に対して、事前学習で用いた画像の各チャンネルの平均値で引くという前処理が入っています。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUJEy3uvv9Di"},"outputs":[],"source":["# [1-6]\n","# チャンネルごとに平均値を引く処理\n","x = preprocess_input(img, ARCH)\n","print(x.shape)\n","\n","plt.imshow(x[0])"]},{"cell_type":"markdown","metadata":{"id":"DZ2Jg5pnJf-e"},"source":["平均値を引いているため全体的に暗くなっている。この変換を行うことで学習通りの性能を実現できる。\n","\n","次に学習済みのモデルに対して、正規化された画像を入力して認識結果を得る。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"buYoQH803Le2"},"outputs":[],"source":["# [1-7]\n","# 学習済みのモデルを使用し、自前データを予測する。\n","# predict_on_batchはpredictよりも早いので採用している\n","output = model.predict_on_batch(x)"]},{"cell_type":"markdown","metadata":{"id":"fElgK5Sr1pVU"},"source":["結果は1000次元の（numpyの配列形式：numpy.ndarray）ベクトルで、合計が１の確率を表している。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEpdMKnaKKM6"},"outputs":[],"source":["# [1-8]\n","# 出力形式を確認\n","print(type(output))\n","print(output.shape)\n","\n","# 最初の10クラスの出力を見てみる\n","print(output[0, 0:10])\n","\n","# 合計値を確認\n","print(f\" 1000次元の出力の合計値は　{np.sum(output[0])}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Sl9AhUYJqBD"},"outputs":[],"source":["# [1-9]\n","# その結果、推定されたトップ10種類の名前を確率とともに表示。\n","pred = decode_predictions(output, ARCH, top=10)\n","print(\"上位\\t予測ラベル \\t 確率\")\n","for i, (_, label, prob) in enumerate(pred[0]):\n","    print(f\"{i+1}\\t{label.ljust(20)}\\t{prob}\")"]},{"cell_type":"markdown","metadata":{"id":"sMsRk_OC-ALb"},"source":["# 課題 B2-3-1 事前学習モデルの性能確認\n","様々な入力画像を用意し、事前学習モデルの予測結果を確認し、以下について考察せよ。\n","- 予測が間違えた場合なぜそのような結果になったのか\n","- 上位の10個に出てきたラベルを見て考えられること\n","\n","ヒント : 以下のコードを使用することで画像読み込みから、予測の表示までを行える。\n","```\n","# 以下の\"\"の間に新しくアップロードした画像のパスを指定\n","img_path = \"\"\n","img = image.load_img(img_path)\n","# 画像の表示\n","plt.imshow(img)\n","# 前処理\n","x = preprocess_input(img, ARCH)\n","# 予測結果の確認\n","output = model.predict_on_batch(x)\n","pred = decode_predictions(output, ARCH, top=10)\n","print(\"上位\\t予測ラベル \\t 確率\")\n","for i, (_, label, prob) in enumerate(pred[0]):\n","  print(f\"{i+1}\\t{label.ljust(20)}\\t{prob}\")\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxs6Ialn75wK"},"outputs":[],"source":["# ここから実験を追加する。(自由にセルを増やしてOK)"]},{"cell_type":"markdown","metadata":{"id":"mJC8EtxT5LWD"},"source":["# 課題 B2-3-2 VGGの畳み込み層の構造\n","畳み込み層最後のConv5_3の畳み込みフィルタにより得られるfeature mapの1つの値(ピクセル)は入力空間でどのくらいの範囲の影響を受けているか？　また、このことからどんなことが考えられるか？（以下の構造図を踏まえて考えよ）\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1l4qf_ohJpsagRznuFkt2C8ETK5gilYxp\" width = 70%></img>\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}